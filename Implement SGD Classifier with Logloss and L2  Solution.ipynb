{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gONY1YiDq7jD"
   },
   "outputs": [],
   "source": [
    "# Standardizing the data.\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(X_train)\n",
    "x_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.09 seconds.\n",
      "Convergence after 10 epochs took 0.09 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
       "              random_state=15, verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    \n",
    "    w = np.zeros_like(dim)\n",
    "    b = 0\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7I6uWBRsKc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "b = 0\n"
     ]
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pv1llH429wG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "  return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    sigmoid = 1 / (1 + np.exp(-z))\n",
    "\n",
    "    return sigmoid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_JASp_NAfK_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "  val=sigmoid(z)\n",
    "  assert(val==0.8807970779778823)\n",
    "  return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logloss(y_true,y_pred):\n",
    "    '''In this function, we will compute log loss '''\n",
    "    sub_sum = 0\n",
    "\n",
    "    for i in range(len(y_true)):\n",
    "        sub_x = y_true[i]*(np.log10(y_pred[i])) + (1 - y_true[i])*(np.log10(1-y_pred[i]))\n",
    "        sub_sum += sub_x\n",
    "    loss = -(sub_sum)/len(y_true)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzttjvBFCuQ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "    loss=logloss(true,pred)\n",
    "    assert(loss==0.07644900402910389)\n",
    "    return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "    \n",
    "    dw = x*(y - sigmoid(np.dot(w, x+b))) - (alpha*w)/N\n",
    "    \n",
    "\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WI3xD8ctGEnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "  assert(np.sum(grad_dw)==2.613689585)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    "def gradient_db(x,y,w,b):\n",
    "    \n",
    "    '''In this function, we will compute gradient w.r.to b '''\n",
    "\n",
    "    db = y - sigmoid(np.dot(w, x+b))\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfFDKmscG5qZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "  grad_db=gradient_db(x,y,w,b)\n",
    "  assert(grad_db==-0.5)\n",
    "  return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train ,X_test, y_test, epochs ,alpha, eta0, tolerace):\n",
    "    \n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "\n",
    "    N=len(X_train)\n",
    "\n",
    "    w, b = initialize_weights(X_train[0])\n",
    "    training_loss = []\n",
    "    test_loss = []\n",
    "    \n",
    "    converged = False\n",
    "    \n",
    "    while not converged :\n",
    "        for every_epoch in tqdm(range(epochs)):\n",
    "\n",
    "            y_predicted_train = []\n",
    "            y_predicted_test = []\n",
    "\n",
    "            for i in range(len(X_train)):\n",
    "                grad_w = gradient_dw(X_train[i], y_train[i], w, b, alpha, N)\n",
    "                grad_B = gradient_db(X_train[i], y_train[i], w, b)\n",
    "\n",
    "                #Updating weights and intercept\n",
    "                w = w + eta0 * grad_w\n",
    "                b = b + eta0 * grad_B\n",
    "\n",
    "\n",
    "            for i in range(len(X_train)):\n",
    "                y_pred_train = sigmoid(np.dot(w,X_train[i])+b) #changed here, using sigmoid\n",
    "                y_predicted_train.append(y_pred_train)\n",
    "\n",
    "            loss_train = logloss(list(y_train), y_predicted_train)\n",
    "            training_loss.append(loss_train)\n",
    "\n",
    "            #predicting y_test with updated values of w and b\n",
    "            for i in range(len(X_test)):\n",
    "                y_pred_test = sigmoid(np.dot(w,X_test[i])+b)\n",
    "                y_predicted_test.append(y_pred_test)\n",
    "\n",
    "            loss_test = logloss(y_test, y_predicted_test)\n",
    "            test_loss.append(loss_test)\n",
    "\n",
    "            if every_epoch != 0 and (training_loss[every_epoch-1] - training_loss[every_epoch]) <= tolerace:\n",
    "                max_epoch = every_epoch\n",
    "                converged = True\n",
    "                print(\"Converged at {0} th epoch with tolerance = {1} \".format(every_epoch, tolerace))\n",
    "                break\n",
    " \n",
    "    return w,b,training_loss,test_loss, y_predicted_train, max_epoch\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [00:14<02:10,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at 5 th epoch with tolerance = 1e-05 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs=50\n",
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "tolerace = 0.00001\n",
    "w,b,training_loss,test_loss, y_predicted_train, max_epoch  = train(X_train,y_train,X_test,y_test,epochs,alpha,eta0, tolerace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABJc0lEQVR4nO3deXxU1fn48c+TnaxIwpIFQ4KAYhICQZAdpe6gVqt1r7WC9Fc3UKu2VtFvF1t3Wzdc27qhVhDccI2sCgmyBDHIKiGswYQkQBKS8/vjTpJJmGSy3MkkM8/79ZoXM/fMvfc8XMiTc8+554gxBqWUUqqlArxdAaWUUl2LJg6llFKtoolDKaVUq2jiUEop1SqaOJRSSrWKJg6llFKtoolDqRYSESMiJ3Tg+fo5zhlkw7G2icjP7KiXUpo4VJfk+EF4WETKnF7/8na9lPIH7f5NRikvmmKM+czblVDK32iLQ/kcEblWRJaKyD9FpEREvheRSU7lCSIyX0QOiMgmEZnqVBYoIn8Qkc0iUioiuSLS1+nwPxORH0TkJxF5SkTExfkTHK2hHk7bhorIfhEJFpETROQrR932i8icFsbVXL27ici/HfXaICK/F5GCJo4TKiKPi0ih4/W4iIQ6yuJE5H0RKXacZ7GIBDjK7hSRnY6/l3znv1PlX7TFoXzVSOAdIA64CHhXRFKMMQeAN4D1QAJwIvCpiGwxxnwOzAQuB84FNgIZwCGn404GTgGigVxgAfCx84mNMYUishy4GHjesfkK4B1jTJWI/B/wCXAaEAIMb2FMzdX7PqAfkApEAB82c5w/AqcCmYAB3gPuAf4E3AYUAD0d3z0VMCIyCLgROMURXz8gsIX1Vj5GWxyqK5vn+M249jXVqWwv8LgxpsoYMwfIB85ztB7GAncaY44YY1YDLwBXO/a7HrjHGJNvLGuMMUVOx33QGFNsjPkR+BLrh68rr2MlIBytkssc2wCqgGQgwVGHJe4CbUG9LwX+aoz5yRhTADzZzOGuBB4wxuw1xuwD7nc6ThUQDyQ7/u4WG2tCu2ogFBgsIsHGmG3GmM3u6q18kyYO1ZVdaIzp7vR63qlsp2k4g+d2rN/UE4ADxpjSRmWJjvd9geZ+IO52en8IiGzie+8Ao0QkARiP9Zv9YkfZ7wEBVojIehG5rpnz1XJX7wRgh1OZ83tXx9re6DgJjvcPAZuAT0Rki4jcBWCM2QTcCswC9orIm47YlB/SxKF8VWKj/ofjgULHq4eIRDUq2+l4vwPo396TG2OKsW5HXYp1m+qN2kRmjNltjJlqjEkAbgCebsEwX3f13gUkOZU598u4OlZyo+MUOupWaoy5zRiTCkwBZtb2ZRhjXjfGjHXsa4C/u6mz8lGaOJSv6gXc7OiMvgQ4CfjQGLMDWAb8TUTCRCQD+A3wmmO/F4D/E5EBYskQkdg21uF14Bqsvo7a21SIyCUiUvtD/iesH8LVzR2oBfV+C7hbRI4TkUSs/oimvAHcIyI9RSQOuBd41VG3yY7OewEOOupVLSKDROR0Ryf6EeCwuzor36WJQ3VlCxo9xzHXqewbYACwH/gL8AunvorLsTqSC4G5wH3GmE8dZY9i/RD+BOsH54tAtzbWb76jDnuMMWuctp8CfCMiZY7v3GKM2dqC4zVX7wewOrW3Ap9h3SqraOI4fwZygLXAOmCVYxuO+n4GlAHLgaeNMdlY/RsPYv197sZKzH9oQZ2VDxJdyEn5GhG5FrjecVvFL4nIb4HLjDETvF0X5Xu0xaGUDxCReBEZIyIBjqGzt2G1SpSynT7HoZRvCAGeA1KAYuBN4GlvVkj5Lr1VpZRSqlX0VpVSSqlW8YtbVXFxcaZfv35t2reiopDQUP96zklj9g8as39oT8y5ubn7jTE9G2/3i8TRr18/cnJy2rRvaWkuUVFZNteoc9OY/YPG7B/aE7OIbHe1XW9VKaWUahVNHG7k5rZ04lLfoTH7B43ZP3giZk0cSimlWsUv+jiUUr6lqqqKgoICjhw50qr9YmI+YsOGDR6qVefUkpjDwsJISkoiODi4RcfUxOFGcvJ93q5Ch9OY/UNXjrmgoICoqCj69euHi0UYm1RREeOHo6qaj9kYQ1FREQUFBaSkpLTomHqrqilr34LH0kj59+PwWJr12U+kpMzydhU6nMbctRw5coTY2NhWJQ3A75IGuI9ZRIiNjW1V600Thytr34IFN0PJDpaNOgglO6zPfpI8li3zv/9cGnPX09qkAVBWtsb9l3xMS2Ju7d+lJg5XPn8Aqg4D0Ge3455f1WFrux+orNzl7Sp0OI3ZPxhT5e0qdDhPxKyJw5WSgrq3KVtDXW5XSvmvoqIiMjMzyczMpE+fPiQmJtZ9rqysbHbfnJwcbr755ladr1+/fuzfv789VbaVdo67EpNk3Z4CjIAYp+1+IDJymLer0OE0Zv8QEBBuy3FiY2NZvXo1ALNmzSIyMpLbb7+9rvzo0aMEBbn+8Tp8+HCGD++450nsirnBMW0/oi+YdC8EW4u+BRjHvb+gMGu7Hxg+PNfbVehwGrNvm/ftTsY8+AVp/7eVMQ9+wbxvd7rfqZWuvfZaZs6cyWmnncadd97JihUrGD16NEOHDmX06NHk5+cDkJ2dzeTJkwEr6Vx33XVMnDiR1NRUnnzyyRafb/v27UyaNImMjAwmTZrEjz/+CMDbb79NWloaQ4YMYfz48UREDGb9+vWMGDGCzMxMMjIy+OGHH9oVqyYOVzIuhSlPQkxftqQ4Rhr0G2tt9wP5+dO8XYUOpzH7rnnf7uTud9exs/gwBthZfJi7313nkeSxceNGPvvsMx555BFOPPFEFi1axLfffssDDzzAH/7geqXd77//noULF7JixQruv/9+qqpa1idx4403cs0117B27VquvPLKuttfDzzwAAsXLmTNmjXMnz+fI0e28eyzz3LLLbewevVqcnJySEpq390TTRxNybgUZuTxY3IlZFwG25dBeZH7/XzArl3Pe7sKHU5j9l0PLczncFV1g22Hq6p5aGG+7ee65JJLCAwMBKCkpIRLLrmEtLQ0ZsyYwfr1613uc9555xEaGkpcXBy9evViz549LTrX8uXLueKKKwC4+uqrWbJkCQBjxozh2muv5fnnn6e6upqqqv2MGjWKv/71r/z9739n+/btdOvWrV1xauJoibEzoOoQfPOst2uilGqlwuLDrdreHhEREXXv//SnP3HaaaeRl5fHggULmnxOIjS0fgBOYGAgR48ebdO5a4fUPvvss/z5z39mx44dZGZmUlRUzBVXXMH8+fPp1q0bZ511Fl988UWbzlFLE0dL9DoRTpwMK56DIwe9XRulVCskdHf923VT2+1SUlJCYmIiAK+88ortxx89ejRvvvkmAK+99hpjx44FYPPmzYwcOZIHHniAuLg4du7cw5YtW0hNTeXmm2/m/PPPZ+3ate06tyYON0aNctwHHTcTjpRAzoverVAHqIvZj2jMvuuOswbRLTiwwbZuwYHccdYgj57397//PXfffTdjxoyhurra/Q5uZGRkkJSURFJSEjNnzuTJJ5/k5ZdfJiMjg//+97888cQTANxxxx2kp6eTlpbG+PHjOfXUXzBnzhzS0tLIzMzk+++/55prrmlXXfxizfHhw4ebti7ktH//AuLiplgf/nMh7MmDW9fVjbryRQ1i9hMac9eyYcMGTjrppBZ/f963O3loYT6FxYdJ6N6NO84axIVDEz1Yw86jqqqY4ODubr/n6u9URHKNMceMHdYWRxNqh+/l5Z1fP3xv/O1Qvg++fdXb1fOovLzzvV2FDqcx+7YLhyay9K7TWfvH3iy963S/SRoAR45ssv2YmjhccB6+d/hot/rhewf6Qd+RsPQJqPa/qQuUUgo0cbjkPHzv/mWPAY7he59shHG3WU+Vr3vbm1VUSimv0cThgvMwvd2HkhpuH3Am9E6DxY9CTfs7vDqjgQOf83YVOpzG7B9CQ5O9XYUO54mYNXG40OzwPRFrhFXRD7BhQQfXrGMkJPjHE8XONGb/EBLS09tV6HCeiFkThwvOw/euOukZAEICA+qH7w2+EHr0h8WPgA+OSsvObv06B12dxuwfSkvbNrqyK/NEzJo4XLhwaCJ/uyidxO7dGJf0GQECA3pH1o/ECAi0nibfvRY2fe7dyiqlOlx7plUHa6LDZcuWuSx75ZVXuPHGG+2usq00cTShdvheaGAFN08awPrCg/ywp7T+Cxm/hOhEq9WhlPIrtdOqr169munTpzNjxoy6zyEhIW73by5xdAWaONyIjZ3MNaP6ERYcwPOLt9QXBIXA6Jvhx2XWBIg+JDZ2srer0OE0Zh+39i14LI3IR34Gj6V5ZBno3NxcJkyYQFZWFmeddRa7dlkrLD755JMMHjyYjIwMLrvsMrZts2arfeyxx8jMzGTx4sUtOv6jjz5KWloaaWlpPP744wCUl5dz3nnnMWTIENLS0pgzZw4Ad911V90577nnGdtj1YWc3EhPtzrALx3elzdW/MhtZw6id3SYVTjsGlj0kNXqSB7txVraqzZmf6Ix+7C1b8GCm6HqMALWcPoFjhX4bFoqwRjDTTfdxHvvvUfPnj2ZM2cOf/zjH3nppZd48MEH2bp1K6GhoRQXF9O9e3emT59+zOJPzcnNzeXll1/mm2++wRjDyJEjmTBhAlu2bCEhIYEPPvgAsObHOnDgAHPnzuX7779HRCguLrYlRmfa4nBj3TprSobrx6ZSXWN4aenW+sKQcBj1/2DTZ1C42jsV9IDamP2JxuzDPn8AqhrNhFt12Npuk4qKCvLy8jjjjDPIzMzkz3/+MwUF1lLTGRkZXHnllbz66qtNrgrozpIlS/j5z39OREQEkZGRXHTRRSxevJj09HQ+++wz7rzzThYvXkxMTAzR0dGEhYVx/fXX8+677wL2z0mmicONoqL3ATg+Npxz0+N5/esfKT3i9NT4KddDaDQsedRLNbRfbcz+RGP2YSUFrdveBsYYTj755Lp+jnXr1vHJJ58A8MEHH/C73/2O3NxcsrKy2jRtelNzCg4cOJDc3FzS09O5++67eeCBBwgKCmLFihVcfPHFzJs3jwsuuLY9obnk0cQhImeLSL6IbBKRu1yUnygiy0WkQkRud9o+SERWO70Oisitjfa9XUSMiMR5MgZnN4zvT2nFUd5Y8WP9xrAYGDEVvpsP+zZ2VFWUUi0V08Rqd01tb4PQ0FD27dvH8uXLAaiqqmL9+vXU1NSwY8cOTjvtNP7xj39QXFxMWVkZUVFRlJaWujlqvfHjxzNv3jwOHTpEeXk5c+fOZdy4cRQWFhIeHs5VV13F7bffzqpVqygrK6OkpIRzzz2Xxx9/nLVr7f+55LHEISKBwFPAOcBg4HIRGdzoaweAm4GHnTcaY/KNMZnGmEwgCzgEzHU6dl/gDOBHOlB6Ugyj+8fy4pKtVB6tqS8Y+VtrTfKlj3dkdZRSLTHp3mNnsw7uZm23SUBAAO+88w533nknQ4YMITMzk2XLllFdXc1VV11Feno6Q4cOZcaMGXTv3p0pU6Ywd+7cJjvHX3nllbop1JOSkujVqxfXXnstI0aMYOTIkVx//fUMHTqUdevW1a0l/pe//IV77rmH0tJSJk+eTEZGBhMmTOBvf5thW5y1PDatuoiMAmYZY85yfL4bwBjzNxffnQWUGWMedlF2JnCfMWaM07Z3gP8D3gOGG2P2N1eX9kyr3thXG/fxq5dW8NAvMrhkeN/6go/uhJUvwM3fQvfjbTmXUsq11k6rztq3rD6NkgKrpTHpXts6xn1Fa6ZV9+SoqkRgh9PnAmBkG45zGfBG7QcROR/YaYxZU7tUoisiMg2YBpCQENPgKdmsLCuJ5ObW/30kJ99HSsosli1LoLLSGkYXGTmMhIQbKC3NqVuf2RgY1PsznvlyDbGlyQSIlXhP7P93+qwUdr41iB8GWktExsZOJj19AevWTWlwP3niRENh4Ww2bryhblta2nyiorJYvrx+uuf4+KkMGjSbnJwsyspWARASEs/o0YVs3TqL7dvvb1NMw4fnkp8/rcGa06NG7aS0NLfBVNsDBz5HQsK0Bn93vhpTbOwUiooW+FRMvnidamM6evR3lJaWAxAVNZzKyn1UVGyv+25Y2AkEBoZTXu5Y6S4lleDfvk9AQARVVfuoqTkEpTmIBBMZOYSKikIqKwvr9g8Pt36AHjq0oW5bSEgCoaEJlJWtwRirnzMgIJyIiMEcObKNqqr6318jIjKorj7UYErz0NBkQkJ6NniSOzAwhvDwARw69APV1SV121sUExAcHEdYWD/Ky7+zYoI2x3TkyC6yswc3uE5NMsZ45AVcArzg9Plq4J9NfHcWcLuL7SHAfqC343M48A0Q4/i8DYhzV5esrCzTVl9+yTHb3l21wyTf+b75fMPuhgXzfmfMAz2NObj7mH26Elcx+zqNuWv57rvv2rTfwYMrba5J59fSmF39nQI5xsXPVE92jhcATvdySAIKm/huU84BVhlj9jg+9wdSgDUiss1xzFUi0qeddW2VyRkJJMSE8exXWxoWjJ0BNVXw9dMdWR2l/JLxwXnivKW1f5eeTBwrgQEikiIiIVi3nOa38hiX43SbyhizzhjTyxjTzxjTDys5DTPG7Lar0i0RHBjAb8alsmLrAb798af6gtj+1gSIK1+Ewz81ub9Sqn3CwsIoKirS5GEDYwxFRUWEhYW1eB+P9XEYY46KyI3AQiAQeMkYs15EpjvKn3W0FHKAaKDGMeR2sDHmoIiEY42cusH1GTpGWprrXHfZKX158vMfmL1oC89clVVfMG4mrH8XVjwPE37fQbW0V1Mx+zKNuWtJSkqioKCAffv2tWq/6mohMHCD+y/6kJbEHBYWRlJSy4cne3TKEWPMh8CHjbY96/R+N9btJlf7HgJi3Ry/X/tr2byoqCyX2yNCg7jq1ON5OnszW/eXkxIXYRX0SYcBZ1m3q079fxAa6ekq2q6pmH2Zxty1BAcHk5KS0ur9KioKCQ1N8ECNOi9PxKxPjrvhPNKksV+N7kdwYKPJDwHG327dqlr1bw/XzjOai9lXacz+QWO2hyaOdugVFcbFw5J4J7eAfaUV9QV9R0C/cbDsn3C0oukDKKVUF6SJo52mjkuhqrqG/yzf1rBg3Ewo3QVr3nC5n1JKdVWaONyIj5/abHlqz0jOHNyb/yzfTnmF0+RlqadBwlBY8jhUt35SM29yF7Mv0pj9g8ZsD49NOdKZ2DnliCurfvyJi55exr2TB3PdWKcOuw0LYM5VcNELkHGJx86vlFKe0NSUI9ricCMnx/3Ik2HHH8eIfj14cclWqqqdJj8cdB70PNGacr2mpukDdDItidnXaMz+QWO2hyYON2rn6XFn2vhUdhYf5sN1u+o3BgTA2Jmw9zvY+LGHami/lsbsSzRm/6Ax20MTh01OP7EXJ/SK5NmvtjR8mjXtYmu23MUPWzMkKqVUF6eJw42QkPgWfS8gQJg2PpUNuw6y+AenWd4Dg2DMrbAzF7Yu8kwlbdbSmH2JxuwfNGZ7aOe4jSqOVjP+H18yoFcUr17vNIN81RF4Ygj0HAi/WuDxeiillB20c7yNtm6d1eLvhgYF8usxKSzZtJ+8nfVz6xMcBqNvtFocO1baX0mbtSZmX6Ex+weN2R6aONxwXrCmJa4YeTyRoUE8t6jRNCRZv4aw7tYIq06utTH7Ao3ZP2jM9tDEYbPosGCuHHk8H6wtZMeBQ/UFoZFw6m8h/0PYs957FVRKqXbSxOEBvx6TQmCA8OKSrQ0LRkyD4AhY8ph3KqaUUjbQxOFG7XrKrdEnJowLMhN5c+WPHCivrC8I7wGnXAd5/4OizTbW0l5tibmr05j9g8ZsD00cHjJtfCpHqmr47/LtDQtG3QgBwbD0Ce9UTCml2kkThxu5uceMRGuRgb2jmHRiL/69fBtHqqrrC6L6wNCrYPXrcLC1S7B3jLbG3JVpzP5BY7aHJg4PmjY+lQPllbydW9CwYMzNYGpg2b+8UzGllGoHTRweNCKlB5l9u/P8oi1U1zg9aHlcP0i/BHJfhvIir9VPKaXaQhOHG8nJ97V5XxFh+oRUfjxwiI/zdjcsHDsDqg7BN8+0s4b2a0/MXZXG7B80ZnvolCMeVl1j+NmjXxEdFsS8341BROoL51wFWxbBjDwIi/ZK/ZRSqik65UgbLVuW0K79AwOE68elsKaghK+3HGhYOHYmVJRAzovtOofd2htzV6Qx+weN2R6aONyorNzl/ktuXDwsibjIEJ5b1OjZjcRh0P90WP4UVB1u93nsYkfMXY3G7B80Znto4ugAYcGBXDu6H9n5+/h+98GGheNug/J98O2r3qmcUkq1kiYONyIjh9lynKtOTSY8JJDZjSc/TB4DfUdaDwRWV9lyrvayK+auRGP2DxqzPTRxuDF8eK4tx+keHsIvT+nL/NWFFBY73ZYSsVodJTtg7Vu2nKu97Iq5K9GY/YPGbA9NHG7k50+z7Vi/GZuCAV5qPPnhgDOhd7o1+WFNtct9O5KdMXcVGrN/0JjtoYnDjV27nrftWEnHhTMlI543VvxIyWGn21IiMG4mFP0AG7y/QqCdMXcVGrN/0JjtoYmjg00b35/yympe+6bR5IeDL4Ae/WHxI+AHz9YopbouTRwdbHBCNOMGxPHy0kaTHwYEWk+T714Lmz73XgWVUsoNjyYOETlbRPJFZJOI3OWi/EQRWS4iFSJyu9P2QSKy2ul1UERudZQ9JCLfi8haEZkrIt09GcOoUTttP+b0Cf3ZV1rBvG8bHTvjlxCdBIsftv2creGJmDs7jdk/aMz28FjiEJFA4CngHGAwcLmIDG70tQPAzUCDn5TGmHxjTKYxJhPIAg4Bcx3FnwJpxpgMYCNwt6diACgttX9Ewuj+saQlRjN78RZqnCc/DAqxZs79cTlsX2b7eVvKEzF3dhqzf9CY7eHJFscIYJMxZosxphJ4E7jA+QvGmL3GmJVAcw8wTAI2G2O2O/b5xBhz1FH2NZBkf9Xr5eWdb/sxRYRp4/uzZV85n23Y07Bw6NUQHmf1dXiJJ2Lu7DRm/6Ax2yPI9iPWSwR2OH0uAEa24TiXAW80UXYdMMdVgYhMA6YBJCTEkJ1dP7lg7VKKzgucJCffR0rKLJYtS6h7RL/2wZn8/GkNRiaMGrWT0tLcBhdk4MDnSEiY1uA8sbGTSU9fwLp1Uygqer9u+8SJhszY94nrFsg/FvyXkH2/Jy1tPlFRWSxfnsjxvUNI3bSfbct/Qb9R75CTk0VZ2SoAQkLiGT26kK1bZ7F9+/1timn48Fy3MWVnS6tjKiyczcaNN9Rtc46pVnz8VAYNmu2VmJq7ToDPxdSS65SdLT4XU3PXCfC5mFpynbKzpU0xNckY45EXcAnwgtPnq4F/NvHdWcDtLraHAPuB3i7K/oh1+0rc1SUrK8u01Zdf0uZ93Xll6VaTfOf7ZuXWooYFh4uN+WuSMXOu9ti5m+PJmDsrjdk/aMytA+QYFz9TPXmrqgDo6/Q5CWjtWqnnAKuMMQ3u54jIr4DJwJWO4Dxm4MDnPHbsS4Yn0T08mOcaT0MSFgMjpsJ382FfvsfO3xRPxtxZacz+QWO2hycTx0pggIikiEgI1i2n+a08xuU0uk0lImcDdwLnG2MO2VLTZiQkeO5J0/CQIK4Z1Y9Pv9vDpr1lDQtP/X8QFAZLHvfY+ZviyZg7K43ZP2jM9vBY4jBWB/aNwEJgA/CWMWa9iEwXkekAItJHRAqAmcA9IlIgItGOsnDgDODdRof+FxAFfOoYqvusp2IAGtyP9IRfjUomNCiA5xu3OiLiIOtaWDsHftrucl9P8XTMnZHG7B80Znt4snMcY8yHwIeNtj3r9H43TYyKcrQmYl1sP8HmanpVbGQolw7vy5yVO7jtzIH0ig6rLxx9I6x8AZb9E87z7rMdSilVS58c7wSuH5fC0ZoaXl62rWFBTBIMuQxW/QdK97jcVymlOpomDjdqh2p6UnJsBOekxfPq19spPdLokZaxM6CmCr5+2uP1qNURMXc2GrN/0JjtIR4elNQpDB8+3OTk5Hi7Gs1as6OYC55ayh/PPYmp41MbFr5zHWz8BGasg27HeaeCSim/IyK5xpjhjbdri8ONdeumdMh5hvTtzqjUWF5aupXKozUNC8fOhMpSWNExU0J3VMydicbsHzRme2jicMP5aU5PmzYhlV0lR1iwptHjLn3SYODZ1u2qijLXO9uoI2PuLDRm/6Ax20MTRycycWBPBvWO4rlFmznmFuK42+DwT7Dq396pnFJKOWji6EREhBsmpLJxTxnZ+fsaFvYdAf3GWUNzj1Z4p4JKKYUmDrcmTuzYwQNThiSQEBPGc4s2H1s47jYo3QWrX/doHTo65s5AY/YPGrM9NHG4UVg4u0PPFxwYwHVjU/h6ywFW7yhuWJg6ERKGwdLHofqoi73t0dExdwYas3/QmO2hicMN52mNO8plI44nKiyI2Y1bHSJWq+OnbbB+rst97eCNmL1NY/YPGrM9NHF0QpGhQVx9ajIf5e1m2/7yhoWDzoWeJ8KSR6GmxvUBlFLKgzRxdFLXju5HcEAALyxpNPlhQID1XMfe72Djx96pnFLKr2nicCMtrbUzwdujV3QYFw1L5O2cAvaXNRpFlXYxdE+GxQ+DB57891bM3qQx+weN2R6tThwiElA79bk/iIrK8tq5p45PpbK6hv80nvwwMAjG3go7c2HrV7af15sxe4vG7B80Znu0KHGIyOsiEi0iEcB3QL6I3GF7bToh5/V9O1r/npGccVJv/vP1dg5VNhpFNeQKiOwDix+x/bzejNlbNGb/oDHbo6UtjsHGmIPAhVjraxyPtYa48rAbJqRSfKiKt1buaFgQHGat17F1EexY6Z3KKaX8UksTR7CIBGMljveMMVWA/z1J4wVZyT0Ynnwczy/eytHqRqOosn4NYd2tEVZKKdVBWpo4ngO2ARHAIhFJBg56qlKdSXz8VG9XgRsm9Gdn8WE+WLerYUFoJJz6W8j/EPast+18nSHmjqYx+weN2R5tXo9DRIIc64p3el1hPY7m1NQYznjsK8KCA3n/prGIOK0hfOgAPJ5uzZ77ixe9V0mllM9p13ocInKLo3NcRORFEVkFnG57LTuhnBzvj8IICBCmjU9lfeFBlm4qalgY3gOGXwfr34UiF/NbtUFniLmjacz+QWO2R0tvVV3n6Bw/E+gJ/Bp40PbadEJlZau8XQUALhyaSM+oUNeTH476HQQEw9InbDlXZ4m5I2nM/kFjtkdLE0ftvZFzgZeNMWuctqkOEBoUyHVjUlj8w37ydpY0LIzqA0OvsmbNPVjo+gBKKWWTliaOXBH5BCtxLBSRKMAvJkoKCYn3dhXqXDHyeCJCAnl+8ZZjC8fcDKYGlv2r3efpTDF3FI3ZP2jM9mhR57iIBACZwBZjTLGIxAKJxpi1ttfIA7p657izv3zwHS8t3Ub27RPp2yO8YeHc6fDde3BrHkTEeqeCSimf0a7OcWNMDZAE3CMiDwOju0rSaK+tW2d5uwoNXDc2BQFeXLL12MKxM6DqMHzzTLvO0dli7ggas3/QmO3R0lFVDwK3YE038h1ws4j8zfbadELbt9/v7So0EB/TjQsyE5mzcgc/lVc2LOw5CE6aDN/MhiNtf8yms8XcETRm/6Ax26OlfRznAmcYY14yxrwEnA2cZ3ttVItMG5/K4apqXv16+7GFY2dCRQnk6DMdSinPaM3suN2d3sfYXA/VCoP6RHHaoJ68smwbR6qqGxYmDoP+p8Pyp6zbVkopZbOWJo6/Ad+KyCsi8m8gF/ir56rVeWRldc5O9Rsm9KeovJJ3cguOLRx3O5Tvg1X/bdOxO2vMnqQx+weN2R4t7Rx/AzgVeNfxGgW46J1VHWVkSg+G9O3OC4u3UF3TaGRc8mjoe6r1QODRStcHUEqpNmrxrSpjzC5jzHxjzHvGmN3A2+72EZGzRSRfRDaJyF0uyk8UkeUiUiEitzttHyQiq51eB0XkVkdZDxH5VER+cPx5XEtjaIvc3GNGonUKIsIN41PZVnSIT9bvblwI426DgwWwzu1lOkZnjdmTNGb/oDHboz1Lxzb75LiIBAJPAecAg4HLRWRwo68dAG4GHnbeaIzJN8ZkGmMygSzgEDDXUXwX8LkxZgDwueOzXzrr5D4kx4bz7FebOeZ5nAFnQO90WPIY1FS7PoBSSrVBexKHuycHRwCbjDFbjDGVwJvABQ0OYMxeY8xKoKqZ40wCNhtjaocQXQD82/H+31hrhPilwABh6rhU1hSU8M3WAw0LRWDcTCj6ATYs8E4FlVI+Kai5QhFZgOsEIYC7R5MTAedl6wqAka2qneUy4A2nz72NMbvAun0mIr1c7SQi04BpAAkJMWRn1zeQajuLnJtwycn3kZIyi2XLEqistNa9iIwcRnLyfeTnT2PXrufrvjtq1E5KS3PJyzu/btvAgc+RkDCtwXliYyeTnr6AdeumUFT0ft32iRMNhYWz2bjxhrptaWnziYrKarDMY3z8VAYNmk1OTlbdRGUhIfGMHl3I1q2z2L79fnpVhxAV8hJPf/EtJ/c8rmFMff9ESuwJlH38a3L2/hzEimn48Fy3MWVni9diast1aklMzV2n5OT7fC6mllyn7GzxuZiau07Jyff5XEwtuU7Z2dKmmJrS7JQjIjKhyULAGPNVM/teApxljLne8flqYIQx5iYX350FlBljHm60PQQoBE42xuxxbCs2xnR3+s5Pxphm+zl8acoRV578/Ace/XQjC28dz6A+UQ0Lv30V3vsdXPmOdftKKaVaqE1Tjhhjvmru5eacBUBfp89JWEmgNc4BVtUmDYc9IhIP4PhzbyuP2SrLliV48vC2uPrUZLoFBzJ7kYvJD9MvhegkWPxIi4/XFWK2m8bsHzRme7R0ypF1IrK20WuxiDzmmPDQlZXAABFJcbQcLgPmt7J+l9PwNhWOY/zK8f5XwHutPGar1DbfOrPjIkL45Sl9eW/1TnaVNHroLyjEmjn3x+WwfVmLjtcVYrabxuwfNGZ7tLRz/CPgA+BKx2sBsBjYDbziagfHsrI3AguBDcBbxpj1IjJdRKYDiEgfESkAZmJNoFggItGOsnDgDKznRpw9CJwhIj84yv1iQSl3fjM2BQO8vHTbsYVDr4bwuFa1OpRSqinNdo47GWOMGeP0eZ2ILDXGjBGRq5rayRjzIfBho23POr3fjXULy9W+h3DRAW+MKcIaadUhIiOHddSp2qVvj3DOS4/n9W9+5HennUBMt+D6wpBwa5XAz++HwtWQkNnssbpKzHbSmP2DxmyPlrY4IkWkbkSUiIwAIh0fj9peq05k+PBcb1ehxaaNT6Ws4iivf/PjsYWn/AZCY1rU6uhKMdtFY/YPGrM9Wpo4rgdeEJGtIrINeAG4XkQisOax8lnNDUnrbNISYxg3II6Xl26l4mijh/7CYmDEVOuZjn35zR6nK8VsF43ZP2jM9mjpXFUrjTHpWKsAZhpjMhzbyo0xb9leq07EeWx2VzBtfCp7Syt471sXA9hO/S0EhcGSx5s9RleL2Q4as3/QmO3R0lFVMSLyKNYUH5+JyCMiolOrd0JjT4hjcHw0zy3aTE3jyQ8j4iDrWlg7B35ysZaHUkq1QEtvVb0ElAKXOl4HgZc9VSnVdiLCDRNS2byvnM+/d/GIy+ibQAJg2T87vnJKKZ/Q0sTR3xhzn2PeqS3GmPuBVE9WrLMYNWqnt6vQauelx5PYvRuzF20+tjAmETIvh1X/gdI9x5bTNWNuL43ZP2jM9mhp4jgsImNrP4jIGMAvlpcrLe16ozCCAgO4flwKK7f9RO72A8d+YcytUFMFXz/lcv+uGHN7acz+QWO2R0sTx3TgKRHZ5hhV9S/ghuZ38Q3Ok5R1Jb88pS/dw4N57isX05DE9oeTfw4rX4TDPx1T3FVjbg+N2T9ozPZo6aiqNcaYIUAGkGGMGQqcbnttlG3CQ4K45tRkPt2wh837yo79wtiZUFkGK/xvlIlSqn1atR6HMeagMeag4+NMD9RH2eia0f0ICQzghcUuWh190mDg2fD101DhIrEopVQTPLYCoK8YOPA5b1ehzeIiQ/lFVhL/y93J3tIjx35h3O3WrapV/26wuSvH3FYas3/QmO3R7Hocze4o8qMx5nib6+MRvr4eR3O27S/ntEey+e2E/vz+7BOP/cIrk6FoE9yyBoJCO76CSqlOq03rcYhIqYgcdPEqBfxiYnvn1bq6on5xEZyT1odXv95OWYWLacXG3Qalu2D163WbunrMbaEx+weN2R7uFnKKMsZEu3hFGWNaOrOu8rJp4/tz8MhR3lzhYvLD1ImQMAyWPg7VPj1fpVLKJu3p41BdRGbf7oxM6cGLS7ZSVV3TsFDEanX8tA3Wz/VK/ZRSXYsmDjdiYyd7uwq2mD6hP7tKjrBgjYvJDwedCz1PgiWPQk2Nz8TcGhqzf9CY7dHmzvGuxJ87x2sZYzj78cWIwEe3jEOk0X3PtW/Bu1PhstfhxPO8U0mlVKfSps5xBevWTfF2FWwhIkwdn8r3u0v5auO+Y79w8kXW8rJvX8u6t4PhsTQrmfgJX7nOraEx+wdPxKyJw42iove9XQXbnD8kgT7RYa6nIVn/LhwpgepKqoMMlOyABTf7TfLwpevcUhqzf/BEzJo4/EhIUAC/GZvC8i1FrC0oblj4+QPWxIfAwI1h1raqw9Z2pZRyoonDz1w2oi9RoUE8t6hRq6OkoO5tYLVT/0fJjg6qmVKqq9DE4cbEib41eCAqLJgrT03mo3W72F5UXl8Qk1T3NrTS6Z+FBMLGTzqwht7ha9e5JTRm/+CJmDVxuFFYONvbVbDdr8f0IygggBcWb63fOOleCO4GQGF8pbUtMAQie8Hrl8A710GZixUFfYQvXmd3NGb/4ImYNXG4sXGj7y070js6jJ8PTeTt3B0UlVVYGzMuhSlPQkxfNg46AjF94YKnrDmsJv4BNiyAf50Cq/4LPjiE2xevszsas3/wRMyaOPzU1PEpHKmq4T/Lt9dvzLgUZuRZ72fkWZ+DQmHinTB9KfQaDPNvhH9Pgf2bvFNxpZTXaeLwUyf0iuJnJ/XmP8u3caiyBXNU9RwI134AU56AXWvhmdGw6CE4Wun5yiqlOhVNHG6kpc33dhU8ZvqEVH46VMXbOQUNtjcZc0AAZF0LN66AE8+FL/4MsyfAjhWer6yH+fJ1borG7B88EbMmDjeiorK8XQWPGd6vB1nJx/HCki0cdZr80G3MUX3gklfg8jethwZfPBM+uB2OHGx+v07Ml69zUzRm/+CJmDVxuLF8eaK3q+BR08ansuPAYT7K2123rcUxDzoHfvcNjLwBVr4AT42EDV3zyVxfv86uaMz+wRMxa+Lwc2ec1JvUuAieW7SZNk14GRoF5/wdrv8cwnvAnCthzlVwcJf9lVVKdQqaOPxcQIAwbXwqeTsPsmxzUdsPlJQF07Jh0n3ww6fw1AirFVJT43ZXpVTX4tHEISJni0i+iGwSkbtclJ8oIstFpEJEbm9U1l1E3hGR70Vkg4iMcmzPFJGvRWS1iOSIyAhPxhAfP9WTh+8ULhyaSFxkaN00JG2OOTAYxs2E3y6DhKHwwW3w8tmw93sba+sZ/nCdG9OY/YMnYvbYehwiEghsBM4ACoCVwOXGmO+cvtMLSAYuBH4yxjzsVPZvYLEx5gURCQHCjTHFIvIJ8Jgx5iMRORf4vTFmYnN10fU43Hvqy008tDCfD28ex+CE6PYf0BhY8wYs/ANUlFkJZexMCA5r/7GVUh3CG+txjAA2GWO2GGMqgTeBC5y/YIzZa4xZCVQ1qmw0MB540fG9SmNMce1uQO1PthjAxZJ29snJ8Y9RGFeNTCY0KICLn1nGK++dwJgHv2DetzvbfkARyLwCbsyBtIvgq7/Ds2Nh21L7Km0jf7nOzjRm/+CJmINsP2K9RMB5atUCYGQL900F9gEvi8gQIBe4xRhTDtwKLBSRh7ES32hXBxCRacA0gISEGLKz62d8zcqyWh+5ufWJNDn5PlJSZrFsWQKVlVbHbmTkMMrKVpGfP41du56v++6oUTspLc0lL+/8um0DBz5HQsK0BueJjZ1MevoC1q2b0mBO/IkTDYWFsxtMBZCWNp+oqKwGIyDi46cyaNBscnKyKCtbBUBISDyjRxeydesstm+/v00xDR+ee0xMJVE5HBdayN5DPYkMOchfTp3Ea1/fBNxJ95L6CRDbFFOP5zkuI5CBG/Pp9sq5MOwavo1bTEnlGo/G1JrrVFa2qktcJ7v/7WVni8/F1Nx1Kitb5XMxteQ6ZWdLm2JqiidvVV0CnGWMud7x+WpghDHmJhffnQWU1d6qEpHhwNfAGGPMNyLyBHDQGPMnEXkS+MoY8z8RuRSYZoz5WXN1ac+tquxs8YsZNcc8+AU7iw8DMC7xUxbvPAOAxO7dWHrX6facpLIcsh+E5U9BeKw1Guvkn1utEy/zl+vsTGP2D+2J2Ru3qgqAvk6fk2j5baUCoMAY843j8zvAMMf7XwHvOt6/jXVLzGNCQuI9efhOo9CRNIC6pNF4e7uFRMCZ/wfTvoToBHjn1/DGZVDs/TU//OU6O9OY/YMnYvZk4lgJDBCRFEfn9mVAi559N8bsBnaIyCDHpklAbad6ITDB8f504Af7qnys0aM92oXSaSR07+Zye3RYMDU1Nv+GFj/Eeu7jzL/A1kXWg4NfPwM11faepxX85To705j9gydi9ljiMMYcBW4EFgIbgLeMMetFZLqITAcQkT4iUgDMBO4RkQJHxzjATcBrIrIWyAT+6tg+FXhERNY4tjV9I84GW7fO8uThO407zhpEt+BAAC484TUAAgRKjlTxy9nL2bq/vLndWy8wCEbfCP/va0geBR/fBS/8DHavs/c8LeQv19mZxuwfPBGzx/o4OhPt42iZed/u5KGF+fzl1En88evPuf3MgdQYuH/BeiqO1nDHWYP49ZgUAgNs7pMwBvL+ZyWPQwdg9E0w8a66haU6gj9d51oas3/oan0cqou5cGhiXUf40rtO5+fDkrg4K4lPZ05gzAlx/PmDDfzyueVs2Vdm74lFIP0X8LsVkHk5LH0cnh4Fm7+09zxKKVto4lBu9Y4O48VfDefRS4ewcU8p5zyxmBcWb6Ha7r6P8B7WqoO/WmAlk/9eCHOnQ3k7pkJRStlOE4cbtWOf/YmrmEWEi4ZZrY+xjtbHpZ5ofQCkjLemLRl3O6x7G546BdbM8eiStXqd/YPGbA9NHKpVekeH8YKj9fGDJ1sfwd1g0p/ghkVwXArMnQavXgQHttp7HqVUq2nicMP5KUt/4S7m2tbHZzMnMG5AfetjsydaH71Pht98Auc+DDtWWn0fS5+A6hYsd9sKep39g8ZsD00cqs16RYfx/DXDefyXmWzaW8a5Tyzm+UUeaH0EBMKIqdaiUf1Pg0/vhecnws5V9p5HKdUimjhUu4gIFw5N5NMZ4xk3oCd/+XADv3h2GZv2eqD1EZMIl70Ol/4XyvbBC5PgY8fsu0qpDqOJw43k5Pu8XYUO15aYrdZHFo//MpMt+8o598nFzF602f7WhwgMPh9uXAFZ18LXT1m3rzZ+0q7D6nX2DxqzPfQBQGW7vaVH+OPcPD79bg9Dj+/OQ78Ywgm9Ij1zsu3LYcEtsD8f0i6Gsx+EyF6eOZdSfkYfAGyjZcsSvF2FDtfemHtFhTH76iyeuCyTrfut1sdzX3mg9QHWdCXTF8PEP8CGBfCvU2DVf1s9dFevs3/QmO2hicON2jnq/YkdMYsIF2Qm8smM8Uwc2JO/ffQ9Fz/job6PoFCYeCdMXwq9BsP8G+HfU2D/phYfQq+zf9CY7aGJQ3lUr6gwnnO0PrYVWa2PZz3V+ug5EK79AKY8AbvWwjOjYdFDcLTS/nMp5cc0cbgRGTnM/Zd8jN0x17Y+Pp0xgdMG9eTButZHqa3nASAgwOo0v3EFnHgufPFnmD0Bdqxodje9zv5BY7aHdo6rDmWMYcHaXdz3Xh7lldXMPGMg149NISjQQ7/D5H8EH9wGBwvhlOth0r0QFu1+P6WUdo63VXPr7voqT8YsIpw/JIFPZkzg9EG9rNbHs8v5YY8HWh8Ag86xHhwceQOsfMFaNGrD+8d8Ta+zf9CY7aGJww3nBej9RUfE3DMqlGeuGsY/Lx/Kj0XlnPfkEp7J3szR6hr7TxYaZa1vfv3n1gy8c66EOVfBwV2w9i14LM2K+bE067Of0H/b/sETMQfZfkSlWkhEmDIkgVH9Y/nTvDz+/vH3fJy3i4cvGcKA3lH2nzApC6Zlw7J/wld/hx+GQs1RqKmyykt2wIKbrfcZl9p/fqV8hLY4lNfFRYby9JXD+NcVQ9nx02HOe3IJT2dv8kzrIzAYxs20pm03NXVJo0eR43eoqsPw+QP2n1cpH6Kd425UVBQSGupfDw15M+b9ZRXc+14eH67bzZCkGB66ZAgDPdH6AJgV03TZhLsgfgjEZ0B0ojXViY/Rf9v+oT0xN9U5rreq3CgtzfW7f2jejNlqfWTxwdpd/Om9PCY/uYRbfjaAG8an2j/yKqavdXsKKIk+SsxBx3+HgCBY9A+rRQIQHgt9MhyJxPE6LsUa+tuF6b9t/+CJmLXF4YYubu89+8squO+99XywbhcZSTE89IshDOpjY+tj7VtWn0bVYbInHmRidrS1gNSUJ+HE82DPeti1pv61d0N9f0hIFPRJd0omGRA3CAK7zu9ineU6dySNuXW0xaG6nLjIUJ66chjnrt3Fve/lMeWfNrc+ajvAP38AWG+1QCbdW7+97wjrVetoJezb4Egka60/c1+Bo4et8qAwa+Ep59ZJr8EQHNb+uirViWjiUJ3eeRnxnJrag3vnr+ehhfl8nLebhy+xqfWRcan1yhaYkdf8d4NC6hNCrZpqKNrUsGWS9y7kvmyVBwRBzxMbJpM+adYQYaU8ae1b1i9FQ7GGmjv/UtROmjjcGDjwOW9XocN1xphjI0N56ophnJe+iz/Ny2PyPxdzy6QBTJ/Q35bWR5tjDgiEnoOsV+1/SmOgeHvDlsmmz2DN646dBGL7H9tvEt6j3XG0Rme8zp7mNzE73YYdmB9m+1Bz7eNQXU5RWQX3zV/P+2t3kZ4Yw0OXZHBiny4wjUjpbqdkstr6s+TH+vKYvo4WSUZ9v0lUvE+O6FI2qCiD8r1Qvh/K9lrvy/ZB+T749tX6W6jOYvq6b1k7aaqPQxOHG9qZ1nl9tG4X98zL4+CRKm4+fQDTJ/YnuI2tD6/FfOgA7F7bsHVStAlw1CWi57HJ5LgUW5JJV7nOdurUMRsDR4odP/z3OpLBfqf3++r/LN8HVYdcH6fbcXD4p7qPOVllDM+tXUhNYFZxi6uknePK55yTHs/I1Fjum7+eRz7dyMLvrL6PLtH6qBXeA1InWq9aFWWwJ69hMtnypPWUO0BojJVAnG91xQ2wbpupzqWmGg4V1bcIXLUOnN/XjtpzJgEQHmetbBnRE3qk1r+v/bP2fXic1Rf3WFrdUPOyKKcHaWOSbAlLE4fq0npEhPDPy4dyXnof7plnjbxqb+vD60Ij4fhTrVetoxWw97uGySTnJacRXd2sTvcGI7pOsha5asyDnaadlp0xH62o/62/udZB+T4raRgXMyAEhjj9wO8NvdMhojY59ILIntafET2tXy5a+0vBpHvr+jjqBHeztttAE4cbsbGTvV2FDtcVYz47LZ4RKfWtj4/XW62Pk+Jb1vro9DEHhULCUOtVq/ooFP3QMJmsextyXrTKA4Kh14mOW12OZLJ/I3x0B1QdJnZ/kH/Mz+XUUdxkzJXljW4HNdM6OFLi+jzBEY4f+D2t24l9RziSQC8rKdS97wlhMZ7tu3Iaah67P//YoebtpH0cyud8nGf1fZQcruKm0wfw267c+mitmhoo3tYwmexaA4f2N79fSCQMvQpw/DCr+6EmDX/AOW+v+9zcPq343jH7NN6/jcf+6h9W30FjgSHW4IPm+gvCYhr+wHe+PdR4W0iE62N0YV7pHBeRs4EngEDgBWPMg43KTwReBoYBfzTGPOxU1h14AUjD6im8zhiz3FF2E3AjcBT4wBjz++bq0Z7EsW7dFNLTF7Rp367KF2L+qbySWQvW897qQk5OiOahXwxhcELTrQ9fiLlJxkDpLiuBvHFZ3eajgYagaqekEFo7d5ep36/J947vOb9vzfe8xGAQnGJOv8RxS8jVbaI417f6upj2/Nvu8M5xEQkEngLOAAqAlSIy3xjzndPXDgA3Axe6OMQTwMfGmF+ISAgQ7jjuacAFQIYxpkJEenkqBoCiomMX/fF1vhDzcREhPHHZUM5Nj+ePc/M4/19LuOn0Afy/01y3Pnwh5iaJQHSC9XKan2vJuFJrmhVo9TBNWxgPJaXG33tmNBzcCcBXE0qZ+JVTzBe/YGdEnZIn/m17sv0+AthkjNlijKkE3sT6gV/HGLPXGLMSaDCUQESigfHAi47vVRpjih3FvwUeNMZU1B7DgzGoLu6sk/vw6YzxnJcRz2OfbeSCfy3lu8KD3q6W90y61+okdWZjp2mriON2UkCA1fkbEGjN9RUYZE1/HxTieIVar+Awq67B3SAk3PGKsAYThEZaT+OHRllLA4fFWK9u3eFns+pjrm1seCtmH+HJzvFEYIfT5wJgZAv3TQX2AS+LyBAgF7jFGFMODATGichfgCPA7Y7k04CITAOmASQkxJCdXd88zcqyblvl5ta3wJKT7yMlZRbLliVQWbkLqF/kPT9/WoNVtEaN2klpaS55eefXbRs48DkSEqY1OE9s7GTS0xewbt2UBll/4kRDYeFsNm68oW5bWtp8oqKyWL48sW5bfPxUBg2aTU5OFmVlqwAICYln9OhCtm6dxfbt97cppuHDc93GlJ0tPhXTz/vA8UNP5bX8uzn/X0uYnPoqk1PfJijgaF3HeFeLqVarr9ORz9h4yDpm9sSDpEVOJ2rQWJY77d/lYnJ3ncZA/P7jAMgZUUlZ+EE48EtClt3adWNqxXXKzpY2xdQUj/VxiMglwFnGmOsdn68GRhhjbnLx3VlAWW0fh4gMB74GxhhjvhGRJ4CDxpg/iUge8AVwC3AKMAdINc0Eop3jqlbxoUpmzV/PvNWFnBQfzXnpfXhjxQ4Kiw+T0L0bd5w1iAuHJro/kFJ+oKk+Dk/eqioA+jp9TgIKW7FvgTHmG8fnd7A60GvL3jWWFUANEGdDfV0qLJztqUN3Wr4cc/fwEB6/bCizr85i50+HePiTjewsPszYxIXsLD7M3e+uY963O71dzQ7hy9e5KRqzPTyZOFYCA0QkxdG5fRkwvyU7GmN2AztEZJBj0ySgtlN9HnA6gIgMBEIAN2MN2865qegv/CHmM0/uQ0RI/Z3ab3ZPAOBwVTX3L1jP9qJyfH2ouj9c58Y0Znt4rI/DGHNURG4EFmINx33JGLNeRKY7yp8VkT5ADhAN1IjIrcBgY8xB4CbgNUfS2QL82nHol4CXHLesKoFfNXebSqmm7D54pO79hKSFfLrdGrvx06EqJjyUTffwYNITY8js252MpO4MSYqhV7SuraGUR58cN8Z8CHzYaNuzTu93Y93CcrXvauCYe2uOEVpX2VpR5ZcSundjZ7E1JcOVJz1flzh6RoYy88yBrNlRzJqCEp7O3kx1jfW7SZ/oMIb0jXEkku6kJ8UQ0y3YazEo5Q065YgbaWkturvmU/wl5jvOGsTd767jcFU1j+f+CYBuwYH88byTuHBoIpePOB6Aw5XVrC8sYU1BCWsLillbUMLC9XvqjpMaF0FGkiOZ9O3OyQnRhAV3/gkH/eU6O9OY7aGJw42oqCxvV6HD+UvMtaOnHlqYz/aDJ5DYxKiqbiGBDO/Xg+H96hdaKjlUxdqdVhJZvaOY5VuKmLfaGvsRFCAM7B3FkL4xDEmybnMN7B1pz3K3NvKX6+xMY7aHzlXlRqeev99DNOa22XPwiOP2lpVQ1uwo5uARayr0sOAATk6wEkntra5+seGIFxdp0uvsH9oTs67HoZSH9Y4O48yT+3DmyX0AMMawvegQawqKWbPDus31+ortvLTUmmY7OiyIIX27193myuzbnd7a+a5sMu/bnTy0MJ+/nApjHvzC1meUNHEo5SEiQr+4CPrFRXBBpvUf9mh1DRv3lLG2wOp4X7OjmGe/2lLX+d47OrRuBNeQvt3JSOxOTLh2vqvWmfftzrr+u+qagLpnlABbkocmDjfi46d6uwodTmP2nKDAAAYnRDM4IZrLRljbjlRVs77woJVMdli3uT79rr7zvV9seF3H+5CkGE5OiKFbSPs73/U6dz3VNYbiQ5UUlVeyv6yCorJKDpRXUlRWwX7Hn0VllazeUcxRxy8jc/KtJxkOV1Xz0MJ8WxKH9nEo1QmVHK5iXUGJo7/ESia7SqznTgIDhAG9IuueL8lIimFQnyj/WXPEhxhjOHjkaP0P/7JKisrrE0Jtcqjd9tOhSmpc/MgOEGs1zNiIUGIjQ1i2ucjl+QTY+uB5La6f9nG0UU5OFsOH53q7Gh1KY/a+mG7BjB0Qx9gB9bPp7D14pG5I8JqCEj7K282bK615REODAjg5IdrRMrH6TFJiIwgIOLbzvfbe99STpvH8htl+NT9XR1znw5XV7C+rsJJBuSMZlFmJ4UB5ZYOWQVF5BVXVrn95jw4LIi7SSgSpcZGc0i+E2IgQYh3bYiNCiYsMoUdECN3DQwh0utZjHvyi7hmlWaNuYdbyJwDr2SU7aOJwo3bGSX+iMXdOvaLDOGNwGGcM7g1Yv63+eOBQXV/J2oJi5qzcwSvLtgEQFRZU/3yJI6F8vbmIP8zN43BVNf1iNtt+77uzqu8oXtXqjuKq6poGv/3XvW+QAOpbBYcqq10eJzwk0GoVRIbSJzqMkxOirSQQEVKXCGIjQ4iLDOW48BBCgtregnR+RqlfzGbAekbpjrMGudmzZTRxKNVFiQjJsREkx0Zw/pAEwOp837SvrO6p97UFxTy/aEvd/e4Aoe5Wx5c/ng1Y975nzV9PdY0hMEAQsW6HBUjtCwJEmi4LqH9fW+bqe+7KpNH3nM/tquXUUs4dxQA7iw9z1//WsrvkCEP6dqeo3NESKGvYErASQyUlh6tcHjc4UIiNCHUkgxBS4iLqWwS1ycDpfXhIx/24dX5GCWjyGaW20j4ON5YtS2D06JZO6usbNGbfcqSqmu92HWTtjmJmLfjO/Q6dlHOCCWyUVI5JPuL4XoCws/hw3ai1yOASyqpiXB5fBHqEWz/ka1sGcY1uDVl/Wtuiw4K8+hxOS7Xn37ZX1hzvLLRzXCmL871vZ72jQnlr+iiqaww1xroNVm0MNTVQY4zjZY3qMcbUfc+5rKbGen/MMZzKGnzPTZlxfG78vcZlxlGvpo4xt5lp8l+fOrIuIRzXqJ9Aaed4m23dOouUlFnerkaH0ph9l/O97wtPeI15m66kW3Agd597EsmxEd6unkes2HqgLlnWxgzW7ZvR/T22lE+n4Yl/2zp+zw3n5ST9hcbsuy4cmsjfLkonsXs3LjzhDRK7d+NvF6X7dMf4HWcNoptj0skLT3gDsLejuLPzxL9tbXEo5WcuHJrIhUMTyc6GpXed7u3qeJynO4r9kSYOpZTP87dk6Wl6q8qNrCz/61TXmP2DxuwfPBGzJg6llFKtoonDjdzcY0ai+TyN2T9ozP7BEzFr4lBKKdUqmjiUUkq1il88OS4i+4Dtbdw9DthvY3W6Ao3ZP2jM/qE9MScbY3o23ugXiaM9RCTH1SP3vkxj9g8as3/wRMx6q0oppVSraOJQSinVKpo43Jvt7Qp4gcbsHzRm/2B7zNrHoZRSqlW0xaGUUqpVNHEopZRqFU0czRCRs0UkX0Q2ichd3q6Pp4nISyKyV0TyvF2XjiAifUXkSxHZICLrReQWb9fJ00QkTERWiMgaR8z+sRAJICKBIvKtiLzv7bp0BBHZJiLrRGS1iNg606H2cTRBRAKBjcAZQAGwErjcGNN1F212Q0TGA2XAf4wxad6uj6eJSDwQb4xZJSJRQC5woY9fYwEijDFlIhIMLAFuMcZ87eWqeZyIzASGA9HGmMnero+nicg2YLgxxvYHHrXF0bQRwCZjzBZjTCXwJnCBl+vkUcaYRcABb9ejoxhjdhljVjnelwIbAJ9e3cdYyhwfgx0vn//tUUSSgPOAF7xdF1+giaNpicAOp88F+PgPFX8mIv2AocA3Xq6Kxzlu2awG9gKfGmN8PmbgceD3QI2X69GRDPCJiOSKyDQ7D6yJo2niYpvP/2bmj0QkEvgfcKsx5qC36+NpxphqY0wmkASMEBGfvi0pIpOBvcaYXG/XpYONMcYMA84Bfue4FW0LTRxNKwD6On1OAgq9VBflIY77/P8DXjPGvOvt+nQkY0wxkA2c7d2aeNwY4HzHPf83gdNF5FXvVsnzjDGFjj/3AnOxbr/bQhNH01YCA0QkRURCgMuA+V6uk7KRo6P4RWCDMeZRb9enI4hITxHp7njfDfgZ8L1XK+Vhxpi7jTFJxph+WP+PvzDGXOXlanmUiEQ4BnwgIhHAmYBtoyU1cTTBGHMUuBFYiNVp+pYxZr13a+VZIvIGsBwYJCIFIvIbb9fJw8YAV2P9Brra8TrX25XysHjgSxFZi/XL0afGGL8YnupnegNLRGQNsAL4wBjzsV0H1+G4SimlWkVbHEoppVpFE4dSSqlW0cShlFKqVTRxKKWUahVNHEoppVpFE4dSNhCRaqchvavtnE1ZRPr5y4zFqmsI8nYFlPIRhx3TeCjl87TFoZQHOdZE+LtjDYwVInKCY3uyiHwuImsdfx7v2N5bROY61stYIyKjHYcKFJHnHWtofOJ46lspr9DEoZQ9ujW6VfVLp7KDxpgRwL+wZmnF8f4/xpgM4DXgScf2J4GvjDFDgGFA7WwFA4CnjDEnA8XAxR6NRqlm6JPjStlARMqMMZEutm8DTjfGbHFMqLjbGBMrIvuxFpGqcmzfZYyJE5F9QJIxpsLpGP2wpgYZ4Ph8JxBsjPlzB4Sm1DG0xaGU55km3jf1HVcqnN5Xo/2Tyos0cSjleb90+nO54/0yrJlaAa7EWsIV4HPgt1C34FJ0R1VSqZbS31qUskc3x6p6tT42xtQOyQ0VkW+wflG73LHtZuAlEbkD2Af82rH9FmC2Y2biaqwkssvTlVeqNbSPQykPcvRxDDfG7Pd2XZSyi96qUkop1Sra4lBKKdUq2uJQSinVKpo4lFJKtYomDqWUUq2iiUMppVSraOJQSinVKv8f1KcgkgZ8a6oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(max_epoch+1)], training_loss)\n",
    "plt.scatter([i for i in range(max_epoch+1)], training_loss,label='Train Loss')\n",
    "\n",
    "plt.plot([i for i in range(max_epoch+1)], test_loss)\n",
    "plt.scatter([i for i in range(max_epoch+1)], test_loss, label='Test Loss')\n",
    "plt.grid(color='y', linestyle='--', linewidth=1)\n",
    "plt.title(\"Epoch vs logloss \")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"LogLoss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nx8Rs9rfEZ1R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.02252174, -0.00169244,  0.01046409,  0.00020304,  0.03078754,\n",
       "         -0.0082862 ,  0.00323121, -0.00657454, -0.00550897, -0.02467637,\n",
       "         -0.01451406,  0.01074437,  0.01552256,  0.00232928, -0.00441723]]),\n",
       " array([-0.1450079]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUN8puFoEZtU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9276533333333333\n",
      "0.92808\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==========================================================================="
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
